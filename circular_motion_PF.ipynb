{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Particle Filter Demonstration: Circular Motion\n",
    "\n",
    "**Richard Hodgskin-Brown**\n",
    "**First Published September 17th 2022**\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook aims to give a visual demonstration of the bootstrap particle filter algorithm operating on a simple toy model. It is intended as a purely pedagogical exercise to strengthen the intuition behind the algorithm. This is an augmented and generalised version of a similar **[notebook](https://colab.research.google.com/drive/1AoGZAFa_8mG1jQAniV1q8bGZsMQnErzl?usp=sharing)** by Frank Dellaert, with the accompanying text rewritten.\n",
    "\n",
    "In this basic scenario, an object travels on a circular path, and we would like to track its location. We have several pieces of prior knowledge before any measurements take place:\n",
    "\n",
    "- We know the object travels in a perfect circular path around the origin, with no deviations or noise\n",
    "- We know the exact velocity of the object, which is the same no matter its distance from the origin\n",
    "- We have a prior distribution of the location of the object before any measurements in the form of a symmetric multivariate Gaussian centred around a known mean (by deafault, this is at the origin)\n",
    "- We know the exact error distribution on our measurement (i.e. we have a likelihood model)\n",
    "\n",
    "In addition to this, we can take a measurement of the object's location at each timestep. Unfortunately, we are only able to take measurements of the x-coordinate, and there is some degree of noise on each measurement. The goal is to set up a cloud of particles, the distribution of which iteratively closes in on the ground truth of the object location."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Import required libraries (just numerical & plotting libs)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# Setup plotting environment to appear in new window\n",
    "%matplotlib qt\n",
    "sns.set_style('darkgrid') # Favourite darkgrid plotting style"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define Constants\n",
    "\n",
    "Here we'll define the constants for this simulation. These can be altered to get a feel for how the algorithm works."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# Algorithm parameters\n",
    "n_particles = 1000  # Number of particles simulated in the algorithm\n",
    "num_iterations = 10  # Number of iterations of the algorithm before the script stops\n",
    "\n",
    "# Properties of the multivariate Gaussian prior distribution of the object's location\n",
    "prior_mean = (0, 0)  # Coordinates (in m), default is centred around origin\n",
    "prior_covariance = 9  # Value along diagonal of covariance matrix (in m)\n",
    "\n",
    "# Motion_model\n",
    "velocity = 3  # m/s\n",
    "n_euler_steps = 10  # Specifies precision of motion calculation\n",
    "\n",
    "# Observation_model\n",
    "measurement_sigma = 1.0  # standard deviation error (m) on our measurements"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot Aesthetics\n",
    "\n",
    "Here we'll define some variables controlling the figure aesthetics."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# Define colours for plotting\n",
    "light_green = (0.5, 0.9, 0.5)\n",
    "soft_blue = (72/255, 169/255, 247/255)\n",
    "soft_orange = (243/255, 120/255, 6/255)\n",
    "\n",
    "#\n",
    "legend_elements = [Patch(facecolor=soft_blue, edgecolor=tuple(i*0.8 for i in soft_blue)),\n",
    "                   Patch(facecolor=soft_orange, edgecolor=tuple(i*0.8 for i in soft_orange))]\n",
    "legend_labels = ['Prior', 'Posterior']\n",
    "\n",
    "bbox_properties = dict(boxstyle='round', facecolor=(238/255, 238/255, 244/255), alpha=0.5, edgecolor=(212/320, 212/320, 213/320))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "\n",
    "## Creating the Model\n",
    "\n",
    "Particle filters are a tool for solving stochastic problems which can be conceptualised in the language of *state space models*. In this formulation, a state vector describes the properties of the system at any particular time. For example, it may have parameters describing the positions and velocities of moving vehicles, or the abstract space of some complex control system.\n",
    "\n",
    "In addition to the state, we need two further models to describe our system: a _transition_ (or _dynamics_) model, and a _measurement_ (or _observation_) model. The transition model describes how the state evolves over time; usually, discrete points in time are considered, creating a time series, though continuous-time state space models exist. The transition model can be exact, if the dynamics are perfectly known, or (more commonly) describe a probability distribution of values based on the previous state if the evolution is stochastic. Under the Markov condition restriction of state space models, the evolution of the state is dependent on the previous state only. The measurement model describes the relationship between any measured variables and the state itself, including a model of the error on these measurements if present. In this demonstration, we are making a measurement at a rate of one per second.\n",
    "\n",
    "### State\n",
    "\n",
    "In this example, the state $\\textbf{x}_t$ at a given time is fully described using the x and y coordinates ($p_x^t$ & $p_y^t$). The motion is entirely deterministic, and dependent only on these coordinates. The state could alternatively be parameterised in terms of a radius and a phase.\n",
    "\n",
    "$$ \\textbf{x}_t = \\begin{bmatrix} p_x^t \\\\ p_y^t \\\\ \\end{bmatrix}$$\n",
    "\n",
    "### Transition Model\n",
    "\n",
    "The transition model for this demonstration consists of a motion model only, in this case a perfect circular motion trajectory. The scalar velocity $v$ of the object is prior knowledge, and in this demo there is no noise on the trajectory. The state, containing the object position, is updated using the vector velocity $\\textbf{v}_t$ at each timestep. This is calculated using the **[Euler method](https://en.wikipedia.org/wiki/Euler_method)**; there are of course simple analytic solutions to circular motion, but this approach generalises well to more complex motion models.\n",
    "\n",
    "$$\\textbf{x}_{t+1} = \\textbf{x}_{t} + \\textbf{v}_t$$\n",
    "$$\\textbf{v}_t = \\frac{v}{\\sqrt{p_x^t^2 + p_y^t^2}} \\cdot \\begin{bmatrix} -p_y^t \\\\ p_x^t \\end{bmatrix}$$\n",
    "\n",
    "### Measurement Model\n",
    "\n",
    "We are restricting ourselves in this example to a noisy measurement $m^t$ of the x-value only. Over repeated measurements, this is enough to determine the full state of the object. We will construct a model to describe how the measurement is corrupted with noise (we will use simple Gaussian noise here), equivalently, we are defining a *likelihood* $l(p_x^t | m^t)$ of the ground truth x-value $p_x^t$ given the measurement $m^t$. (The normalisation factor can be ignored, as the particle weights which will be calculated using this likelihood will be normalised anyway. This likelihood function only needs to be *proportional* to the probability distribution of the ground truth given a measurement). The standard deviation of the measurement noise $\\sigma_m$ is a parameter which can be set. By default, it is relatively high (1.0 m) to demonstrate the ability of particle filters to converge on a stable estimate of the ground truth despite noisy measurements.\n",
    "\n",
    "$$l(p_x^t | m^t)=\\exp\\left(\\frac{(p_x^t - m^t)^2}{2\\sigma_m^2}\\right)$$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# Calculate circular motion at the specified velocity for one second\n",
    "def motion_model(samples):\n",
    "    # Simulate all samples forward for one second, using specified number of Euler steps\n",
    "\n",
    "    # Perform motion on copy rather than inplace\n",
    "    predictions = np.copy(samples)\n",
    "\n",
    "    # Calculate velocity over n intermediate steps\n",
    "    for i in range(n_euler_steps):\n",
    "        x = predictions[:, 0]\n",
    "        y = predictions[:, 1]\n",
    "        norm = np.sqrt(x ** 2 + y ** 2)\n",
    "        predictions[:, 0] -= (1 / n_euler_steps) * y * velocity / norm\n",
    "        predictions[:, 1] += (1 / n_euler_steps) * x * velocity / norm\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Define likelihood function. This returns a function - a probability distriubtion - given an input measurement\n",
    "def likelihood_func(measurement):\n",
    "\n",
    "    # Define likelihood function for this measurement\n",
    "    def likelihood(location):\n",
    "        return np.exp(-0.5 * (location[0]-measurement)**2 / (measurement_sigma**2) )\n",
    "\n",
    "    # Return likelihood function\n",
    "    return likelihood\n",
    "\n",
    "# Take a noisy measurement of the ground truth\n",
    "def take_measurement(ground_truth):\n",
    "    return np.random.normal(ground_truth, measurement_sigma)\n",
    "\n",
    "# Sample from the prior distribution defined for the object\n",
    "def sample_prior(n_samples):\n",
    "    sample_mean = np.array(prior_mean)\n",
    "    sample_covariance = np.diag([prior_covariance] * 2)\n",
    "    return np.random.multivariate_normal(sample_mean, sample_covariance, size=n_samples)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Performing a Particle Filer\n",
    "\n",
    "The idea behind the particle filter is very simple. We run a set of parallel simulations, known in the jargon as *particles*, according to the dynamics model we have set up. The initial states are sampled from the prior distribution we established, and their states are updated according to the dynamics model. At each timestep, we take a measurement using our measurement model. We use this measurement to *weight* particles which have higher probability according to our likelihood model. In the bootstrap particle filter approach implemented here, we resample the particles from the current set at each timestep according to their weights. This means that at each step, particles which are closer to the measurements survive, and inaccurate particles are effectively discarded.\n",
    "\n",
    "At each step, we can use the (weighted) distribution of particles to estimate a probability distribution over the unknown state parameters. If the particle filter is set up correctly, this probability distribution should iteratively approximate the ground truth.\n",
    "\n",
    "\n",
    "### Initialisation\n",
    "\n",
    "First, we will randomly sample the ground truth from our prior - in this toy model, our prior is exactly correct. We will sample a set of particles from our prior for simulation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "ground_truth = sample_prior(1)[0]  # Sample ground truth from prior\n",
    "trajectory_radius = np.sqrt(np.sum(ground_truth**2))  # Calculate trajectory radius for plotting\n",
    "samples = sample_prior(n_particles)  # Sample particles from prior"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Recursive Simulation\n",
    "\n",
    "We will now perform the particle filter algorithm. At each iteration, we have a collection of particles which form our prior distribution of the state. A measurement is then made, which is used to weight these particles. These weighted particles create a posterior distribution using the information from the measurement. The motion model is applied to the weighted particles, and they are resampled according to their (normalised) weights. This new set of particles then forms the prior distribution for the next iteration.\n",
    "\n",
    "Each of these steps are plotted on one figure (for each iteration) to demonstrate this process. It can be seen that the posterior distribution after measurement slowly closes in on the ground truth."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "for iter_i in range(num_iterations):\n",
    "\n",
    "    # Create plot grid\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(13, 7))\n",
    "    fig.suptitle(f'Circular Motion Particle Filter Demonstration\\nIteration {iter_i+1}', fontsize=16)\n",
    "    fig.text(0.0, 0.85, 'Prior and Posterior Distributions', ha='left', va='center', fontsize=16, color='g')\n",
    "\n",
    "    # Plot prior distribution of particles\n",
    "    axs[0][0].scatter(samples[:,0], samples[:,1], alpha=0.6, label='Particles')\n",
    "    axs[0][0].set_title('Prior distribution of particles')\n",
    "\n",
    "    # Take a measurement of the ground truth using our measurement model\n",
    "    measurement = take_measurement(ground_truth[0])\n",
    "\n",
    "    # Calculate importance weights as likelihood of measurement\n",
    "    weights = np.apply_along_axis(likelihood_func(measurement), 1, samples)  # Weight for each sample\n",
    "    weights[weights < 1e-10] = 0  # remove very small weights (eliminates plotting errors, realistically these are never sampled)\n",
    "\n",
    "    # Bootstrap sample from weighted particles to calculate posterior distribution\n",
    "    sample_indices = np.random.choice(len(samples), p=weights/np.sum(weights), size=n_particles)  # Select particles to resample\n",
    "    resampled_particles = samples[sample_indices]  # Resample particles (with probability proportional to their normalised weights)\n",
    "\n",
    "    # Plot weighted particles\n",
    "    axs[0][1].scatter(samples[:,0], samples[:,1], c=weights, s=weights*1000, alpha=0.6)\n",
    "    axs[0][1].axvline(measurement, -10, 10, color='red', linestyle='--', label='Measurement')\n",
    "    axs[0][1].set_title('Weighted samples from posterior (using measurement)')\n",
    "\n",
    "    # 2D Seaborn KDE plot of particles\n",
    "    sns.kdeplot(x=samples[:, 0], y=samples[:, 1], ax=axs[0][2], fill=True, bw_method=measurement_sigma)\n",
    "    sns.kdeplot(x=resampled_particles[:, 0], y=resampled_particles[:, 1], ax=axs[0][2], fill=True, bw_method=measurement_sigma)\n",
    "    axs[0][2].set_title('2D KDE plot of prior & posterior distributions')\n",
    "    axs[0][2].axvline(measurement, -10, 10, color='red', linestyle='--')\n",
    "\n",
    "    # Add descriptive text describing second row of plots\n",
    "    fig.text(0.0, 0.438, 'Prediction with motion model', ha='left', va='center', fontsize=16, color='g')\n",
    "    plt.subplots_adjust(hspace=0.3)\n",
    "\n",
    "    # Transform particles according to motion model\n",
    "    predictions = motion_model(samples)  # Particles after motion\n",
    "    unmodified_ground_truth = ground_truth  # Save unmodified ground truth to display on figure\n",
    "    ground_truth = motion_model(ground_truth.reshape(1,2)).reshape(2)  # Transform ground truth\n",
    "\n",
    "    # Plot weighted particles after motion model\n",
    "    axs[1][0].scatter(predictions[:,0], predictions[:,1], c=weights, s=weights*1000, alpha=0.6)\n",
    "    axs[1][0].set_title('Distribution of weighted particles after motion model')\n",
    "\n",
    "    # Bootstrap sample from weighted particles after motion to calculate prior for next iteration\n",
    "    # (could use previous resampled particles here)\n",
    "    sample_indices = np.random.choice(len(samples),p=weights/np.sum(weights),size=n_particles)\n",
    "    samples = predictions[sample_indices]\n",
    "\n",
    "    # Plot resampled particles\n",
    "    axs[1][1].scatter(samples[:,0], samples[:,1], alpha=0.6)\n",
    "    axs[1][1].set_title('Resampled prior for next iteration')\n",
    "\n",
    "    # 2D Seaborn KDE plot of resampled particles after motion\n",
    "    sns.kdeplot(x=samples[:,0], y=samples[:,1], ax=axs[1][2], fill=True, bw_method=measurement_sigma)\n",
    "    axs[1][2].set_title('2D KDE plot of resampled prior')\n",
    "\n",
    "    # Set axis labels and limits (same for all plots to highlight convergence)\n",
    "    # Plot ground truth as scatter point with actual trajectory\n",
    "    for ax_row, ax_i in enumerate(axs):\n",
    "        for ax_j in ax_i:\n",
    "            ax_j.set_xlabel('x (m)')\n",
    "            ax_j.set_ylabel('y (m)')\n",
    "            ax_j.set_xlim(-10,10)\n",
    "            ax_j.set_ylim(-10,10)\n",
    "\n",
    "            # Plot ground truth scatter and circular trajectory\n",
    "            if ax_row == 0:\n",
    "                ax_j.scatter(unmodified_ground_truth[0], unmodified_ground_truth[1], marker='x',\n",
    "                             color=light_green, s=100, label='Ground Truth')\n",
    "            else:\n",
    "                ax_j.scatter(ground_truth[0], ground_truth[1], marker='x',\n",
    "                     color=light_green, s=100, label='Ground Truth')\n",
    "\n",
    "            ax_j.add_patch(plt.Circle((0, 0), trajectory_radius, color=np.array(light_green)*0.8, fill=False,\n",
    "                                      linestyle='--', linewidth=2, label='Trajectory'))\n",
    "\n",
    "\n",
    "    # Create legend from labels in subplots\n",
    "    handles1, labels1 = axs[0][0].get_legend_handles_labels()\n",
    "    handles2, labels2 = axs[0][1].get_legend_handles_labels()\n",
    "    handles1.insert(2, handles2[0])\n",
    "    labels1.insert(2, labels2[0])\n",
    "    handles = handles1 + legend_elements\n",
    "    labels = labels1 + legend_labels\n",
    "    fig.legend(handles, labels, loc='upper right')\n",
    "\n",
    "    # Add descriptive text describing simulation\n",
    "    simulation_text = '\\n'.join([\n",
    "        f'N particles = {n_particles}',\n",
    "        f'N iterations = {num_iterations}',\n",
    "        f'Prior Mean = {prior_mean} (m)',\n",
    "        f'Prior Covariance = {prior_covariance} (m)',\n",
    "        f'Measurement Error = {measurement_sigma} (m)',\n",
    "    ])\n",
    "\n",
    "    # Add descriptive text describing state of simulation\n",
    "    state_text = '\\n'.join([\n",
    "        f'Object Velocity = {velocity} [$ms^{{-1}}]$',\n",
    "        f'Ground Truth = {tuple(unmodified_ground_truth.round(3))}',\n",
    "        f'Posterior Mean = {tuple(np.mean(resampled_particles, axis=0).round(3))}',\n",
    "        f'Measurement = {np.round(measurement, 3)}',\n",
    "        f'GT After Motion = {tuple(ground_truth.round(3))}',\n",
    "    ])\n",
    "\n",
    "    # Plot text in text boxes at top of figure\n",
    "    fig.text(0.005, 0.99, simulation_text, fontsize=14, verticalalignment='top', bbox=bbox_properties)\n",
    "    fig.text(0.766, 0.983, state_text, fontsize=14, verticalalignment='top', bbox=bbox_properties)\n",
    "\n",
    "    # Adjust figure aesthetics\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.8, hspace=0.4)\n",
    "    figManager = plt.get_current_fig_manager()\n",
    "    figManager.window.showMaximized()  # Full screen\n",
    "    plt.show(block=True)  # Show plot, pause simulation until closed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "\n",
    "## Plotting Final Posterior Distributions\n",
    "\n",
    "We will now plot the final posterior distributions to evaluate the performance of the algorithm. The posterior mode is sometimes a better point estimate of the ground truth, though it is a little more involved to calculate this value from the posterior."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# Get posterior from final iteration\n",
    "posterior = resampled_particles\n",
    "\n",
    "# Matplotlib grid plot comparing posterior and ground truth\n",
    "fig = plt.figure()\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "ax2 = plt.subplot(2,2,3)\n",
    "ax3 = plt.subplot(2,2,4)\n",
    "axs = [[ax1], [ax2, ax3]]\n",
    "\n",
    "# 2D Seaborn kde of posterior with ground truth scatter\n",
    "sns.kdeplot(x=posterior[:, 0], y=posterior[:, 1], ax=axs[0][0], fill=True, color='orange',bw_method=measurement_sigma)\n",
    "axs[0][0].set_title('Posterior KDE Plot with Ground Truth', fontsize=16)\n",
    "axs[0][0].scatter(unmodified_ground_truth[0], unmodified_ground_truth[1], marker='x', c='green', s=100, label='Ground Truth')\n",
    "axs[0][0].scatter(posterior.mean(axis=0)[0], posterior.mean(axis=0)[1], marker='x', c='red', s=100, label='Posterior Mean')\n",
    "handles, labels = axs[0][0].get_legend_handles_labels()\n",
    "handles = [legend_elements[1]] + handles\n",
    "labels = ['Posterior'] + labels\n",
    "axs[0][0].legend(handles, labels)\n",
    "axs[0][0].set_xlabel('x (m)', fontsize=16)\n",
    "axs[0][0].set_ylabel('y (m)', fontsize=16)\n",
    "\n",
    "# 1D KDE plot of posterior x with ground truth\n",
    "sns.kdeplot(posterior[:, 0], ax=axs[1][0], color='orange', bw_method=measurement_sigma, label='Posterior')\n",
    "axs[1][0].axvline(unmodified_ground_truth[0], c='green', linestyle='--', label='Ground Truth')\n",
    "axs[1][0].axvline(posterior.mean(axis=0)[0], c='red', linestyle='--', label='Posterior Mean')\n",
    "axs[1][0].set_title('Posterior x', fontsize=16)\n",
    "axs[1][0].set_xlabel('x (m)', fontsize=16)\n",
    "axs[1][0].legend()\n",
    "\n",
    "# 1D KDE plot of posterior y with ground truth\n",
    "sns.kdeplot(posterior[:, 1], ax=axs[1][1], color='orange', bw_method=measurement_sigma, label='Posterior')\n",
    "axs[1][1].axvline(unmodified_ground_truth[1], c='green', linestyle='--', label='Ground Truth')\n",
    "axs[1][1].axvline(posterior.mean(axis=0)[1], c='red', linestyle='--', label='Posterior Mean')\n",
    "axs[1][1].set_title('Posterior y', fontsize=16)\n",
    "axs[1][1].set_xlabel('y (m)', fontsize=16)\n",
    "axs[1][1].legend()\n",
    "\n",
    "# Finalise figure\n",
    "fig.suptitle(f'Final Posterior Distribution after {num_iterations} Iterations', fontsize=25)\n",
    "figManager = plt.get_current_fig_manager()\n",
    "figManager.window.showMaximized()  # Full screen\n",
    "plt.tight_layout()\n",
    "plt.show(block=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
